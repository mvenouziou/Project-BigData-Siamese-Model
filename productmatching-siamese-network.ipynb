{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle competition: Shopee - Price Match Guarantee \n\n#### Full code is publicly available on Kaggle at www.kaggle.com/mvenou/productmatching-siamese-network\n\n*In this Kaggle challenge our goal is to develop a discriminator network capabale of identifying unique products by partitioning a set of images into distinct groupings. During inference we are provided a dataset consisting of 70,000+ product images, along with perceptual hash codes and user-submitted descriptions. Some products may be featured in up to 50 images in the set and we are to return a CSV file listing each \"post ID\" and the ID from all images containing that same product. Our training set contains 32,000+ of sample data.*\n\n*This is a heavily imbalanced problem. On the data side, we have a classification problem with vastly more classes than positive examples per class. On the technological side we have unconstrained machinery during training, but face CPU / GRU budget constraints (8 hours CPU or 2 hours GPU) for inference. With a 70,000+ image inference data set, this resource limitation is significant.*\n\n---\n\nModel Architecture\n\nMy strategy is to build a One-Shot-Learning model similar to [1], comprised of a (resource-intensive) encoder and a very lightweight discriminator network. This model is trained on \"Siamese pairs\" of examples, where each training sample consists of an anchor image and two comparison images- one image from same classification category and another image with a different classification. This Siamese network alleviates the enormous class imbalance within the dataset. However, instead of using a distance metric to produce a decision boundary as in [1], [2] and [3], I utilize a modified binary classification (sigmoid output) with loss function based on false positives and false negatives, which is discussed as an alternative option in [2].\n\nEncodings for all of the test images will be produced and stored using a modestly sized network. We can then use an extremly light discriminator to categorize images into groups. In this way, while categorizing images may require a huge number of comparisons, this resource-intensive encoding process only occurs once per sample. On the other hand, classification of 70,000 images requires a great many pairwise comparisons that cannot benefit from GPU acceleration. Do to this, I limit my encoding model parameters to a fraction of that used in [3] and run inference on CPU. Encoder training is run on GPU because our resources are only limited during inference.\n\nThe encoder uses a pretrained Tensorflow Hub multi-lingual text embedding network [4] [5] [6] and a newly-trained CNN based on [1] to extract features from the image and its text description. The discriminator takes encoded images, encoded text, and perceptual hash of two images as input, and computes the \"distance\" along each of these features, and outputs an overall distance.\n\n*This model architecture and training strategy is based on \"Learning a Similarity Metric Discriminatively, with Application to Face Verification\" by Sumit Chopra Raia Hadsell Yann LeCun (2005) [1]. The choice of loss metric is based on DeepLearning.ai's Deep Learning Specialization course on Coursera [2], which credits [2]. See the bottom of this readme for additional citations.*\n\n---\n\nData Pipeline\n\nDuring inference we will process (batches) of products through the encoder, one at a time. During training, however, products will be processed three at a time using the \"Siamese\" training structure. These \"product triples\" consist of an anchor product, a matching product and a non-matching product. The main effort in our data preprocessing is creating an efficient pipeline for the product triples of the form [(image1, title1, phash1). (image2, title2, phash2), (image3, title3, phash3)]\n\n---\n\nTraining\n\nProduct triples are fed through the network in product pairs (anchor, match), (anchor, non-match) to yield \"matching distance\" and \"non-matching distance.\" Our goal is to define a decision boundary using this distance metric. There are two approaches suggesed in [2]. One is to think in terms of a true distance metric (as in [1], [2] and [3]. The other approach is to treat this as a binary classification problem (match = 0 / non-match = 1) using a sigmoid output we can interpret as the probability that two images do not match. This idea is presented as an alternative approach in [2].\n\nI chose to use binary classification (to let the network learn its own decision boundary) while maintaining the triplet / siamese structure (to deal with the large class imbalance). In this context our triplet loss function is \"loss = (matching_dist + (1 - non_matching_dist))/2.\"\n\n---\n\nMy Journey\n\nThis being my first Kaggle challenge, my first time working with a large unprepared dataset, and my first time facing serious computational GPU restrains, I learned a great deal working through the project.\n\nMy first major obstacle was developing an efficient data pipeline, as my initial one produced data much too slowly to handle 70,000+ inference samples within a time-restricted environment. This difficulty arose from working with matched Siamese triples of data, which use of Tensorflow's high-level image processing pipeline tools. Instead, I learned to use 'tf.data.experimental.CsvDataset' and low-level data loading tools. This increased my data pipeline speed by a factor of 3 compared to my original implemenatation.\n\nMy second obstacle was in stripping down my encoder network to handle the processing and saving of 70,000+ images in a time-limited environment. My first models included elements of an object localization process and a pretrained Tensorflow Hub image feature extractor, both of which I sadly had to remove due to how much processing time they required. Instead I ended with en encoder model with under 40,000 paramaters, which is tiny compared to what I had been using in my Coursera deep learning specializations.\n\nThe third obstacle was cutting down the number of operations required to classify 70,0000+ products, when each category contained no more that 50 products. My initial, naive approach would require an impossible number of pairwise comparisons. This was very interesting and was my first encounter with using algorithm optimization (ideas I learned working when completing Foobar with Google) in a data science context.\n\nThe fourth obstacle was unexpected NaN results removing all image data from the model. Adding gradient clipping, batch norms and carefully checking all divisions did not remove the problem, which I still have been unable to track down. My makeshift \"running out of time\" solution is to babysit the training process and stop training before NaN's appear.\n\n---\n\nResults\n\nFinally resolving the above challenges and leaving my model to train overnight, I awoke to find that the notebook had shut shut down, erasing my model checkpoints. I do not know why this occured, as I stayed within Kaggle's documented resource limits. After frantically retraining the model up until the last possible minute I found that, although the rules explicitly allowed the use of pretrained models, they prohibited me from installing Tensorflow Text that the Tensorflow Hub embedding [4] required in order to run. Dissapointed and without time to implement an alternative solution, I was not able to submit a solution in time for the competition deadline.\n\nThis of course exposes my own fault in not alloting myself an adequate amount of time to work through unanticipated issues that arose. However, I learned a great deal throughout the process and have come out the better for it regardless of the ultimate outcome.\n\nOne of my main takewaways is the importance of producing a minimal working end-to-end process built before spending too much time experimenting with architecture. I spent several days attempting to build an advanced model with novel ideas (nearly ALL of which I had to strip out after truly understanding my computational resource limitations). Had I first developed a minimal working model under the exact competition restrictions, I would have overcome the unexpected \"nuts and bolts\" obstacles with enough time remaining to produce a good model and satisfactory submission to the challenge.\n\n---\n\nCitations:\n\n    [1] @INPROCEEDINGS{1467314, author={Chopra, S. and Hadsell, R. and LeCun, Y.}, booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, title={Learning a similarity metric discriminatively, with application to face verification}, year={2005}, volume={1}, number={}, pages={539-546 vol. 1}, doi={10.1109/CVPR.2005.202}}\n\n    [2] @misc{author = {Andrew Ng}, title = {Special Applications: Face recognition & Neural Style Transfer}, howpublished = {Available at \\url{https://www.coursera.org/learn/convolutional-neural-networks#syllabus} (2020/05/09)}}\n\n    [3] @article{DBLP:journals/corr/SchroffKP15, author= {Florian Schroff and Dmitry Kalenichenko and James Philbin}, title = {FaceNet: {A} Unified Embedding for Face Recognition and Clustering}, journal = {CoRR}, volume = {abs/1503.03832}, year={2015}}\n\n    [4] Tensorflow Hub pretrained multilingial word embedding model, available at https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3, which in turn credits the two works cited below.\n\n    [5] Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego , Steve Yuan, Chris Tar, Yun-hsuan Sung, Ray Kurzweil. Multilingual Universal Sentence Encoder for Semantic Retrieval. July 2019\n\n    [6] Muthuraman Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model. Repl4NLP@ACL, July 2019.\n\n@mvenouziou\nCommit changes\nCommit summary\nOptional extended description\nCommit directly to the main branch.\nCreate a new branch for this commit and start a pull request. Learn more about pull requests.\n\n    © 2021 GitHub, Inc.\n    Terms\n    Privacy\n    Security\n    Status\n    Docs\n\n    Contact GitHub\n    Pricing\n    API\n    Training\n    Blog\n    About\n\n","metadata":{}},{"cell_type":"code","source":"#### PACKAGE IMPORTS ####\n\n# TF Model design\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub\n!pip install tensorflow_text\nimport tensorflow_text as text \n#import tensorflow_probability as tfp\n#!pip install -q -U tensorflow-addons\n#import tensorflow_addons as tfa\n\n# Visualizations\nimport matplotlib.pyplot as plt\n#!pip install -U tensorboard-plugin-profile\n#%load_ext tensorboard\n\n# data management\nimport numpy as np\nimport pandas as pd\nimport string\n\n# file management\nimport datetime\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters\n\nClass offering easy access to hyperparamaters and file directory structure","metadata":{}},{"cell_type":"code","source":"class ModelParameters:\n    def __init__(self, model_name, cloud_server='kaggle'):\n               \n        # universal parameters\n        self._image_size = (196, 196)  # shape to process images in data pipeline\n                \n        # File Paths\n        if cloud_server == 'colab':  # Google Colab with GDrive\n            from google.colab import drive\n            drive.mount('/content/gdrive')        \n            base_dir = '/content/gdrive/MyDrive/Colab_Notebooks/models/ProductComparison/'\n            self._ds_prep_dir = base_dir + 'data_prep/'\n            self._prep_save_dir = self._ds_prep_dir\n            self._dataset_dir = ''\n            self._labels_dir = self._dataset_dir + 'labels/'\n            self._saved_weights_dir = base_dir + 'saved_weights'\n            os.chdir(base_dir)  \n\n        elif cloud_server == 'kaggle': # Kaggle cloud notebook\n            base_dir = ''  # working directory\n            \n            self._dataset_dir = '../input/shopee-product-matching/'\n            self._ds_prep_dir = '../input/productmatching-shopee/'\n            self._prep_save_dir = base_dir\n            self._saved_weights_dir = '../input/productmatching-siamese-network/saved_weights'\n            self._labels_dir = self._dataset_dir\n                  \n        self._test_images_dir = self._dataset_dir + 'test_images/'\n        self._train_images_dir = self._dataset_dir + 'train_images/'\n        self._test_labels_csv = self._labels_dir + 'test.csv'\n        self._train_labels_csv = self._labels_dir + 'train.csv'\n        self._sample_submission_csv = self._labels_dir + 'sample_submission.csv'\n\n        # set model subfolders (unique for each model name)\n        self._model_dir = model_name\n        \n        # ## checkpoints\n        self._checkpoint_dir = base_dir\n        \"\"\"\n        if not os.path.isdir(self._checkpoint_dir):\n            os.makedirs(self._checkpoint_dir) \n            print('created checkpoint directory:', self._checkpoint_dir)\n        \"\"\"\n        \"\"\"\n        self._saved_predictions_dir = base_dir + 'predictions/'\n        if not os.path.isdir(self._saved_predictions_dir ):\n            os.makedirs(self._saved_predictions_dir ) \n            print('created predictions directory:', self._saved_predictions_dir )\n        \n\n\n        # ## tensorboard logs\n        self._logdir = model_name + '/logs' \n        if not os.path.isdir(self._logdir):\n            os.makedirs(self._logdir) \n            print('created log directory:', self._logdir)\n        \"\"\"\n            \n\n    # functions to access params\n    def image_size(self):\n        return self._image_size\n    def dataset_dir(self):\n        return self._dataset_dir\n    def train_images_dir(self):\n        return self._train_images_dir\n    def test_images_dir(self):\n        return self._test_images_dir   \n    def train_labels_csv(self):\n        return self._train_labels_csv\n    def test_labels_csv(self):\n        return self._test_labels_csv  \n    def saved_predictions_dir(self):\n        return self._saved_predictions_dir \n    def checkpoint_dir(self):\n        return self._checkpoint_dir\n    def saved_weights_dir(self):\n        return self._saved_weights_dir\n    def logdir(self):\n        return self._logdir\n    def model_dir(self):\n        return self._model_dir\n    def ds_prep_dir(self):\n        return self._ds_prep_dir\n    def prep_save_dir(self):\n        return self._prep_save_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PARAMETERS = ModelParameters(model_name='version_1', cloud_server='kaggle')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Dataset for training\n\n#### *During inference we will process (batches) of products through the encoder, one at a time. During training, however, products will be processed three at a time using the \"Siamese\" training structure. These \"product triples\" consist of an anchor product, a matching product and a non-matching product. The main challenge in our data preprocessing is creating an efficient pipeline for the product triples of the form [(image1, title1, phash1). (image2, title2, phash2), (image3, title3, phash3)]*","metadata":{}},{"cell_type":"markdown","source":"### Training / Validation Datasets","metadata":{}},{"cell_type":"code","source":"# load train csv as dataframe\nFULL_TRAIN_DF = pd.read_csv(PARAMETERS.train_labels_csv())\nFULL_TRAIN_DF['id'] = FULL_TRAIN_DF['posting_id']\nFULL_TRAIN_DF = FULL_TRAIN_DF.set_index('id')\nFULL_TRAIN_DF['title'] = FULL_TRAIN_DF['title'].apply(lambda x: x.lower())\nFULL_TRAIN_DF = FULL_TRAIN_DF.rename(columns={'image':'image_path'})\n\n# load test csv as dataframe\nTEST_DF = test_df = pd.read_csv(PARAMETERS.test_labels_csv())\nTEST_DF['id'] = TEST_DF['posting_id']\nTEST_DF = TEST_DF.set_index('id')\nTEST_DF['title'] = TEST_DF['title'].apply(lambda x: x.lower())\nTEST_DF = TEST_DF.rename(columns={'image':'image_path'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train / valid split\ncutoff = int(.2* len(FULL_TRAIN_DF))\nVALID_DF = FULL_TRAIN_DF[: cutoff].sample(frac=1)\nTRAIN_DF = FULL_TRAIN_DF[cutoff :].sample(frac=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Functions to find all sets  of (matching, nonmatching) post ids","metadata":{}},{"cell_type":"code","source":"# function to find all sets  of (matching, nonmatching) post ids\ndef matching_labels(loc_id, data_subset):\n    if data_subset == 'test':\n        df = TEST_DF\n    elif data_subset == 'train':\n        df = TRAIN_DF\n    elif data_subset == 'valid':\n        df = VALID_DF\n           \n    posting_id = df.loc[loc_id]['posting_id']\n    label_group = df.loc[posting_id]['label_group']\n\n    # find all matching and non-matching products\n    match_df = df[df['label_group'] == label_group]\n    matches_array = match_df.index.to_numpy()\n    \n    non_match_df = df[df['label_group'] != label_group]\n    non_match_array = non_match_df.index.to_numpy()\n\n    return matches_array, non_match_array\n\n\ndef get_matches(data_subset):\n    \n    if data_subset == 'test':\n        df = TEST_DF.copy()\n    elif data_subset == 'train':\n        df = TRAIN_DF.copy()\n    elif data_subset == 'valid':\n        df = VALID_DF.copy()\n        \n    df = df.drop_duplicates(subset=['label_group'])\n    \n    matches_df = df['posting_id'].apply(lambda x: matching_labels(x ,data_subset)[0])\n    non_matches_df = df['posting_id'].apply(lambda x: matching_labels(x, data_subset)[1])\n    \n    return matches_df, non_matches_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions to generate triples of post ids","metadata":{}},{"cell_type":"code","source":"# functions to generate triples of post ids\ndef triples_from_row(row_num, selections_per_example, matches_df, non_matches_df):\n    # isolate row\n    match_row = matches_df.iloc[row_num]\n    non_match_row = non_matches_df.iloc[row_num]\n\n    # choose number of selections to make\n    num_selections = match_row.shape[0]  * selections_per_example\n\n    # get matches\n    match_pairs = np.random.choice(match_row, size=2*num_selections, replace=True).reshape(-1,2)\n    non_match_selections = np.random.choice(non_match_row, size=num_selections, replace=True).reshape(-1,1)\n    return np.concatenate((match_pairs[:, :1], match_pairs[:, 1:], non_match_selections), axis=1)\n\n\n# function to create dataframe consisting of the three post ids (anchor, match, non-match)\ndef get_triples_post_ids(matches_df, non_matches_df, selections_per_example=3):\n\n    # initialize container to hold results\n    triples = np.empty((0,3), dtype=str)\n\n    for row_num in range(len(matches_df)):\n        # get triples and update found results\n        temp = triples_from_row(row_num, selections_per_example, matches_df, non_matches_df)\n        triples = np.concatenate((triples, temp), axis=0)\n        \n    return pd.DataFrame(triples, columns = ['post_id_1', 'post_id_2', 'post_id_3'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions to generate product info from post id (image, title, phash)","metadata":{}},{"cell_type":"code","source":"# functions to generate info on a single product (image, title, phash) or (image, title, phash, post id)\ndef product_singles(posting_id, data_subset, return_post_id, return_label_group, inference_df=None):\n    \n    # select df (note: product info is contained in original dataframe)\n    if data_subset == 'test':\n        this_df = TEST_DF\n        image_directory = PARAMETERS.test_images_dir()\n    elif data_subset == 'train':\n        this_df = TRAIN_DF\n        image_directory = PARAMETERS.train_images_dir()\n    elif data_subset == 'valid':\n        this_df = VALID_DF\n        image_directory = PARAMETERS.train_images_dir()\n    elif data_subset == 'inference':\n        this_df = inference_df\n        image_directory = PARAMETERS.test_images_dir()\n\n    # select product\n    row = this_df.loc[posting_id]\n\n    # get info\n    image_path = image_directory + row['image_path']\n    title = row['title']\n    phash = row['image_phash']\n    output = image_path, title, phash\n\n    if return_label_group:\n        label_group = row['label_group']\n        output = image_path, title, phash, posting_id, label_group\n    \n    elif return_post_id:\n        output = image_path, title, phash, posting_id\n    \n    else:\n        output = image_path, title, phash  \n\n\n    return output\n\n\n\ndef get_single_product_info_df(id_column_name, df, data_subset, return_post_id, return_label_group, inference_df=None):   \n    info = df[id_column_name].apply(lambda x: product_singles(x, data_subset, return_post_id, return_label_group, inference_df))\n\n    info_df = pd.concat([pd.DataFrame({'image_path':info.apply(lambda x: x[0]).values}, index=info.index), \n                         pd.DataFrame({'title':info.apply(lambda x: x[1]).values}, index=info.index),\n                         pd.DataFrame({'phash':info.apply(lambda x: x[2]).values}, index=info.index)],\n                        axis=1)\n    \n    # prepare phashes\n    info_df['phash'] = info_df['phash'].apply(lambda x: ' '.join(list(x)))\n    \n    if return_post_id:\n        info_df = pd.concat([info_df, \n                             pd.DataFrame({'posting_id':info.apply(lambda x: x[3]).values}, index=info.index)],\n                            axis=1)\n    if return_label_group:\n        info_df = pd.concat([info_df, \n                             pd.DataFrame({'label_group':info.apply(lambda x: x[4]).values}, index=info.index)],\n                            axis=1)\n    return info_df\n\n\ndef get_triples_product_info_df(triples_df, data_subset, return_post_id=False, return_label_group=False, inference_df=None):   \n\n    product_1_info = get_single_product_info_df('post_id_1', triples_df, data_subset, return_post_id, return_label_group, inference_df)\n    product_2_info = get_single_product_info_df('post_id_2', triples_df, data_subset, return_post_id, return_label_group, inference_df)\n    product_3_info = get_single_product_info_df('post_id_3', triples_df, data_subset, return_post_id, return_label_group, inference_df)\n    \n    def rename_columns(number, df):\n        num = str(number)\n        columns={'image_path':'image_path_' + num, 'title':'title_' + num, 'phash':'phash_' + num, \n                 'posting_id': 'posting_id' + num, 'label_group': 'label_group' + num}\n        return df.rename(columns=columns)\n\n    product_1_info = rename_columns(1, product_1_info)\n    product_2_info = rename_columns(2, product_2_info)\n    product_3_info = rename_columns(3, product_3_info)\n    \n    triples_df = pd.concat([product_1_info, product_2_info, product_3_info], axis=1)\n    \n    return triples_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to load images and prepare phash as int","metadata":{}},{"cell_type":"code","source":"# functions to load images and prepare phash\ndef load_images_as_tensor(image_path, perturb_image):\n   \n    target_size = PARAMETERS.image_size()\n\n    # preprocessing\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_jpeg(image, channels=1)\n    image = keras.layers.experimental.preprocessing.Rescaling(1./255)(image)\n    image = keras.layers.experimental.preprocessing.Resizing(height=target_size[0], width=target_size[1])(image)\n    \n    if perturb_image:  # add random rotation\n        image = tf.keras.layers.experimental.preprocessing.RandomRotation(.3, fill_mode='nearest')(image)\n        \n    return image\n\ndef prepare_phash_as_tensor(phash):\n    # placeholder\n    return phash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Final functions for dataset creation","metadata":{}},{"cell_type":"code","source":"# function to create Dataset for a single product\ndef prepare_singles_ds_from_csv(single_product_csv, return_label_group):\n\n    if not return_label_group:\n        ds = tf.data.experimental.CsvDataset(\n                filenames=single_product_csv, \n                record_defaults=[tf.string, tf.string, tf.string, tf.string], \n                exclude_cols=[0],\n                compression_type=None, buffer_size=None,\n                header=True, field_delim=',', use_quote_delim=True,\n                na_value='')\n\n        ds = ds.cache()\n\n        # load images and update phash\n        def map_fn(x):\n            return (load_images_as_tensor(x[0], False),  # 'image_path'\n                    x[1],  # 'title'\n                    prepare_phash_as_tensor(x[2]),  # 'phash',\n                    x[3]  # product id\n            )\n\n        ds = ds.map(lambda x0, x1, x2, x3: map_fn([x0, x1, x2, x3]),\n                    num_parallel_calls=tf.data.AUTOTUNE)\n    \n    else:\n        ds = tf.data.experimental.CsvDataset(\n                filenames=single_product_csv, \n                record_defaults=[tf.string, tf.string, tf.string, tf.string, tf.string], \n                exclude_cols=[0],\n                compression_type=None, buffer_size=None,\n                header=True, field_delim=',', use_quote_delim=True,\n                na_value='')\n\n        ds = ds.cache()\n\n        # load images and update phash\n        def map_fn(x):\n            return (load_images_as_tensor(x[0], False),  # 'image_path'\n                    x[1],  # 'title'\n                    prepare_phash_as_tensor(x[2]),  # 'phash',\n                    x[3],  # product id\n                    x[4]  # label group id\n            )\n\n        ds = ds.map(lambda x0, x1, x2, x3, x4: map_fn([x0, x1, x2, x3, x4]),\n                    num_parallel_calls=tf.data.AUTOTUNE)\n    \n    ds = ds.batch(1)\n    #ds = ds.prefetch(buffer_size=150)#tf.data.AUTOTUNE)\n\n    return ds\n\n\n# function to create dataset for 3 products\ndef prepare_triples_ds_from_csv(triples_product_csv, perturb_image=True):\n\n    ds = tf.data.experimental.CsvDataset(\n        filenames=triples_product_csv, \n        record_defaults=3*[tf.string, tf.string, tf.string], \n        exclude_cols=[0],\n        compression_type=None, buffer_size=None,\n        header=True, field_delim=',', use_quote_delim=True,\n        na_value='')\n\n    ds = ds.cache()\n    \n    # load images and update phash\n    def map_fn(x):\n        return (load_images_as_tensor(x[0], False),  # 'image_path_1'\n                x[1],  # 'title_1'\n                prepare_phash_as_tensor(x[2]),  # 'phash_1'\n                load_images_as_tensor(x[3], perturb_image),  # 'image_path_2'\n                x[4],  # 'title_2'\n                prepare_phash_as_tensor(x[5]),  # 'phash_2'\n                load_images_as_tensor(x[6], perturb_image),  # 'image_path_3'\n                x[7],  # 'title_3'\n                prepare_phash_as_tensor(x[8])  # 'phash_3'\n        )\n\n    ds = ds.map(lambda x0, x1, x2, x3, x4, x5, x6, x7, x8: \n                map_fn([x0, x1, x2, x3, x4, x5, x6, x7, x8]),\n                num_parallel_calls=tf.data.AUTOTUNE)   \n    ds = ds.batch(1)\n    return ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions above are combined to allow easy dataset generation ","metadata":{}},{"cell_type":"code","source":"# compilation functions\n# to apply above procedures\ndef create_fresh_train_dataframe():\n    train_matches_df, train_non_matches_df = get_matches(data_subset='train')\n    valid_matches_df, valid_non_matches_df = get_matches(data_subset='valid')\n    return train_matches_df, train_non_matches_df, valid_matches_df, valid_non_matches_df\n\ndef create_triples_dataframe():\n    train_triples_df = get_triples_post_ids(train_matches_df, train_non_matches_df)\n    valid_triples_df = get_triples_post_ids(valid_matches_df, valid_non_matches_df)\n    return train_triples_df, valid_triples_df\n\ndef extract_products_from_dataframes(train_triples_df, valid_triples_df):\n    train_product_1 = get_product_triples_info_down_column('post_id_1', train_triples_df, data_subset='train')\n    train_product_2 = get_product_triples_info_down_column('post_id_2', train_triples_df, data_subset='train')\n    train_product_3 = get_product_triples_info_down_column('post_id_3', train_triples_df, data_subset='train')\n    \n    valid_product_1 = get_product_triples_info_down_column('post_id_1', valid_triples_df, data_subset='valid')\n    valid_product_2 = get_product_triples_info_down_column('post_id_2', valid_triples_df, data_subset='valid')\n    valid_product_3 = get_product_triples_info_down_column('post_id_3', valid_triples_df, data_subset='valid')\n    \n    return train_product_1, train_product_2, train_product_3, valid_product_1, valid_product_2, valid_product_3\n\ndef convert_product_triples_to_ds(train_product_1, train_product_2, train_product_3, valid_product_1, valid_product_2, valid_product_3, perturb_image=True):\n    train_triples_ds = create_triples_ds(train_product_1, train_product_2, train_product_3, perturb_image)\n    valid_triples_ds = create_triples_ds(valid_product_1, valid_product_2, valid_product_3, perturb_image)\n    return train_triples_ds, valid_triples_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create test datasets\n(To be used for converting single product to match predictions)","metadata":{}},{"cell_type":"code","source":"# Utility functions for saving generated dataframes and arrays\ndef save_to_csv(filename, df):\n    with open(filename, 'w') as f:\n        f.write(\"New file created\")\n    df.to_csv(filename)   \n    return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compilation functions to apply above procedures\n\n# Triple Products\ndef create_matches_df():\n    train_matches_df, train_non_matches_df = get_matches(data_subset='train')\n    valid_matches_df, valid_non_matches_df = get_matches(data_subset='valid')\n    return train_matches_df, train_non_matches_df, valid_matches_df, valid_non_matches_df\n\ndef create_triples_ID_df(train_matches_df, train_non_matches_df, valid_matches_df, valid_non_matches_df):\n    train_triples_df = get_triples_post_ids(train_matches_df, train_non_matches_df, selections_per_example=3)\n    valid_triples_df = get_triples_post_ids(valid_matches_df, valid_non_matches_df, selections_per_example=3)\n    return train_triples_df, valid_triples_df\n\ndef create_triple_products_df(train_triples_df, valid_triples_df):\n    train_triples_product_df = get_triples_product_info_df(train_triples_df, data_subset='train', return_post_id=False)\n    valid_triples_product_df = get_triples_product_info_df(valid_triples_df, data_subset='valid', return_post_id=False)\n    return train_triples_product_df, valid_triples_product_df\n\ndef create_triples_ds_from_csv(train_triples_product_csv, valid_triples_product_csv, batch_size, perturb_image):\n    triples_ds_train = prepare_triples_ds_from_csv(train_triples_product_csv, perturb_image)\n    triples_ds_valid = prepare_triples_ds_from_csv(valid_triples_product_csv, perturb_image)\n    return triples_ds_train, triples_ds_valid\n\n\n\"\"\"\nfile_dir = PARAMETERS.prep_save_dir()\n\ntrain_matches_df, train_non_matches_df, valid_matches_df, valid_non_matches_df = \\\n    create_matches_df()\n\nsave_to_csv(file_dir + 'train_matches_df.csv', train_matches_df)\nsave_to_csv(file_dir + 'train_non_matches_df.csv', train_non_matches_df)\nsave_to_csv(file_dir + 'valid_matches_df.csv', valid_matches_df)\nsave_to_csv(file_dir + 'valid_non_matches_df.csv', valid_non_matches_df)\n\ntrain_triples_df, valid_triples_df = \\\n    create_triples_ID_df(train_matches_df, train_non_matches_df, valid_matches_df, valid_non_matches_df)\n\nsave_to_csv(file_dir + 'train_triples_df.csv', train_triples_df)\nsave_to_csv(file_dir + 'valid_triples_df.csv', valid_triples_df)\n\ntrain_triples_product_df, valid_triples_product_df = \\\n    create_triple_products_df(train_triples_df, valid_triples_df)\n\nsave_to_csv(file_dir + 'train_triples_product_df.csv', train_triples_product_df)\nsave_to_csv(file_dir + 'valid_triples_product_df.csv', valid_triples_product_df)\n\"\"\"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single Products\ndef create_single_product_df(inference_df=None):\n    if inference_df is None:  # during training\n        test_single_product_df = get_single_product_info_df('posting_id', TEST_DF, 'test', return_post_id=True, return_label_group=False, inference_df=inference_df)\n        train_single_product_df = get_single_product_info_df('posting_id', TRAIN_DF, 'train', return_post_id=True, return_label_group=True, inference_df=inference_df)\n        valid_single_product_df = get_single_product_info_df('posting_id', VALID_DF, 'valid', return_post_id=True, return_label_group=True, inference_df=inference_df)\n        \n        return test_single_product_df, train_single_product_df, valid_single_product_df\n        \n    else:  # for inference\n        inference_single_product_df = get_single_product_info_df('posting_id', inference_df, 'inference', return_post_id=True, return_label_group=False, inference_df=inference_df)\n    return inference_single_product_df\n    \n\ndef create_singles_ds_from_csv(test_single_product_csv=None, train_single_product_csv=None, valid_single_product_csv=None, inference_csv=None):\n    \n    if inference_csv is None:\n        single_ds_test = prepare_singles_ds_from_csv(test_single_product_csv, return_label_group=False)\n        single_ds_train = prepare_singles_ds_from_csv(train_single_product_csv, return_label_group=True)\n        single_ds_valid = prepare_singles_ds_from_csv(valid_single_product_csv, return_label_group=True)\n        return single_ds_test, single_ds_train, single_ds_valid\n    \n    else:\n        single_ds_inference = prepare_singles_ds_from_csv(inference_csv, return_label_group=False)\n        return single_ds_inference\n\n\"\"\"\n# Use this to recreate dataframes / csv files\nfile_dir = PARAMETERS.prep_save_dir()\n\ntest_single_product_df, train_single_product_df, valid_single_product_df = \\\n    create_single_product_df()\n\nsave_to_csv(file_dir + 'test_single_product_df.csv', test_single_product_df)\nsave_to_csv(file_dir + 'train_single_product_df.csv', train_single_product_df)\nsave_to_csv(file_dir + 'valid_single_product_df.csv', valid_single_product_df)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Datasets","metadata":{}},{"cell_type":"code","source":"file_dir = PARAMETERS.ds_prep_dir()\nbatch_size = 1\n\n# load singles datasets from csv\nsingle_ds_test, single_ds_train, single_ds_valid = \\\n    create_singles_ds_from_csv(file_dir + 'test_single_product_df.csv',\n                               file_dir + 'train_single_product_df.csv',\n                               file_dir + 'valid_single_product_df.csv')\n\n# generate triples datasets from csv\ntriples_ds_train, triples_ds_valid = \\\n    create_triples_ds_from_csv(file_dir + 'train_triples_product_df.csv', \n                               file_dir + 'valid_triples_product_df.csv',\n                               batch_size=batch_size,\n                               perturb_image=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test the training data pipeline\nfor temp in triples_ds_train.take(1):\n    print('triples_ds_train:'.upper())\n    print('batch size:', temp[0][0].shape[0])\n    print('image:', temp[0].shape)\n    print('title:', temp[1].shape)\n    print('phash:', temp[2].shape)\n\n# test the testing data pipeline\nfor temp in single_ds_train.take(1):\n    print('\\nsingle_ds_train:'.upper())\n    print('batch size:', temp[0].shape[0])\n    print('image:', temp[0].shape)\n    print('title:', temp[1].shape)\n    print('phash:', temp[2].shape)\n    print('phash:', temp[2])\n    print('post id:', temp[3].shape)\n    print('label group id:', temp[4].shape)  # labels not available in test set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Siamese Model","metadata":{}},{"cell_type":"markdown","source":"## Encoders","metadata":{}},{"cell_type":"markdown","source":"### Title Encoder","metadata":{}},{"cell_type":"code","source":"# Title Encoding - universal language encoder\nclass TitleEmbedding(keras.Model):\n\n    def __init__(self, units, name='TitleEmbedding', **kwargs):\n        super().__init__(name=name, **kwargs)\n        \n        self.units = units\n\n        # layers\n        #self.embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n        self.embed = tf.keras.layers.Embedding(input_dim=10, output_dim=50)\n        self.dense1 = keras.layers.Dense(self.units, activation='relu', \n                                        kernel_initializer= tf.keras.initializers.HeNormal(),\n                                        kernel_regularizer=keras.regularizers.l1_l2(l1=1e-2, l2=1e-1))\n        self.batch_norm1 = keras.layers.BatchNormalization(name='batch_norm')\n        self.batch_norm2 = keras.layers.BatchNormalization(name='batch_norm')\n        self.dense2 = keras.layers.Dense(self.units, activation=None,\n                                         kernel_regularizer=keras.regularizers.L2(l2=10)\n                                        )\n\n    def call(self, inputs):      \n        x = inputs\n        x = self.embed(x)\n        x = self.dense1(x)\n        x = self.batch_norm1(x)\n        x = self.dense2(x)\n        x = self.batch_norm2(x)\n        \n        return x\n    \n    def get_config(self):\n        config = {\"units\": self.units}\n        return config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = TitleEmbedding(10, name='TitleEmbedding')\nfor data in triples_ds_train.take(1):\n    title = data[1]\na(title)\nprint(a.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Phash Encoder","metadata":{}},{"cell_type":"code","source":"# PHash Encoding (processing handled in data pipeline)\ndef pHashEncoder(name='pHashEmbedding'):    \n    phash = keras.layers.Input((), dtype=tf.string, name='phash')\n    \n    vocabulary = list(string.printable)\n    vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_mode='int',\n                    output_sequence_length=16, pad_to_max_tokens=True, vocabulary=vocabulary)\n    \n    # model path\n    inputs = [phash]\n    phash = vectorizer(phash)\n    phash = tf.one_hot(phash, depth=len(vocabulary))\n    outputs = [phash]\n    \n    return keras.Model(inputs, outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pHashEncoder(name='pHashEmbedding').summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Encoders","metadata":{}},{"cell_type":"code","source":"# Component A: CNN image encoder\ndef ImageEncoder(units, input_shape, name='ImageEncoder'):\n\n    # Inputs\n    x = keras.layers.Input(input_shape, name='image')  # image\n    inputs = [x]\n\n    # standardize for CNN. Architecture comes from [1]\n    x = keras.layers.experimental.preprocessing.Resizing(height=196, width=196)(x)  \n    \n    x = keras.layers.Conv2D(3, kernel_size=7, strides=1, activation='relu')(x)  # Conv2D \n    x = keras.layers.MaxPool2D(pool_size=3)(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Conv2D(15, kernel_size=7, strides=1, activation='relu')(x)  # Conv2D \n    x = keras.layers.MaxPool2D(pool_size=2)(x)\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Conv2D(45, kernel_size=6, strides=1, activation='relu')(x)  # Conv2D \n    x = keras.layers.MaxPool2D(pool_size=4)(x)\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Conv2D(250, kernel_size=5, strides=1, activation='relu')(x)  # Conv2D \n    x = keras.layers.BatchNormalization()(x)\n\n    # standardize output shape\n    x = keras.layers.Flatten()(x)\n    x = keras.layers.Dense(units, activation=None, \n                           kernel_regularizer=keras.regularizers.L2(l2=1)\n                          )(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    outputs= [x]\n\n    return keras.Model(inputs, outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImageEncoder(40, input_shape=(196,196,1), name='ImageEncoder').summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Discriminator Network","metadata":{}},{"cell_type":"code","source":"def ProductEncoder(image_units, title_units, image_input_shape, name='ProductEncoder'):\n\n    # Inputs\n    image = keras.layers.Input(image_input_shape, dtype=tf.float32, name='image')\n    title = keras.layers.Input((), dtype=tf.string, name='title', )\n    phash = keras.layers.Input((), dtype=tf.string, name='phash')\n\n    inputs = [image, title, phash]\n\n    # Encodings\n    image = ImageEncoder(image_units, image_input_shape, name='ImageEncoder')(image)  # (batch, image_units)   \n    title = TitleEmbedding(title_units, name='TitleEmbedding')(title)  # (batch, title_units)\n    phash = pHashEncoder(name='pHashEncoder')(phash)  # (batch, 16, vocab_size)\n    \n    # Normalize\n    image = image / 100.0\n    title = title / (100.0 + tf.norm(title, ord='euclidean', axis=-1))\n    phash = phash / 16\n    \n    outputs = [image, title, phash]\n    return keras.Model(inputs, outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ProductEncoder(50, 20, (196,196,1)).summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metric","metadata":{}},{"cell_type":"code","source":"# can be used as (bounded) distance measurement for TripletLoss\n# or a probability estimate that the products do not match (for F1 score)\ndef PseudoMetric(units, encoded_image_shape, encoded_title_shape, encoded_phash_shape, name='PseudoMetric'):\n             \n    # Inputs\n    image_encoding_1 = keras.layers.Input(encoded_image_shape, dtype=tf.float32, name='image_encoding_1')  # (batch, image units)\n    title_encoding_1 = keras.layers.Input(encoded_title_shape, dtype=tf.float32, name='title_encoding_1')  # (batch, title units)\n    phash_1 = keras.layers.Input(encoded_phash_shape, dtype=tf.float32, name='phash_1')  # one-hot encoding (batch, 16, vocab_size) \n    \n    image_encoding_2 = keras.layers.Input(encoded_image_shape, dtype=tf.float32, name='image_encoding_2')  # (batch, image units)\n    title_encoding_2 = keras.layers.Input(encoded_title_shape, dtype=tf.float32, name='title_encoding_2')  # (batch, title units)\n    phash_2 = keras.layers.Input(encoded_phash_shape, dtype=tf.float32, name='phash_2')  # one-hot encoding (batch, 16, vocab_size) \n\n    inputs= [image_encoding_1, title_encoding_1, phash_1, image_encoding_2, title_encoding_2, phash_2]\n   \n    # image distance\n    image_dist = image_encoding_1 - image_encoding_2\n    image_dist = keras.layers.Dense(1, activation='sigmoid')(image_dist)\n\n    # title distance \n    title_dist = title_encoding_1 - title_encoding_2\n    title_dist = keras.layers.Dense(1, activation='sigmoid')(title_dist)   \n    \n    # phash distance  \n    phash_dist = keras.losses.categorical_crossentropy(phash_1, phash_2)\n    phash_dist = tf.reduce_mean(phash_dist, axis=[-1], keepdims=True)\n    \n    # combine metrics\n    metric = keras.layers.Concatenate(axis=-1)([image_dist, title_dist, phash_dist])\n    metric = keras.layers.Dense(1, activation='sigmoid')(metric)  # weighted square-norm\n    \n    # final distance value\n    outputs = [metric]\n\n    return keras.Model(inputs, outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PseudoMetric(units=20, encoded_image_shape=[40], encoded_title_shape=[20], encoded_phash_shape=[16, 100]).summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Combined Model","metadata":{}},{"cell_type":"markdown","source":"# Full Model\n\n#### *In order to alleviate our dataset's enormous class imbalance, product triples are fed through the network in product pairs (anchor, match), (anchor, non-match) to yield (sigmoid output) binary classification probabilites predicting whether or not products match. Our triplet setup allows us to measure the prevalance of false positives and false negatives. Our loss function is the average of these errors for each (batch) of product triples.*\n\n#### *The model is written as a Tensorflow subclass model with custom training and inference steps hard-coded in. Precision and Recall metrics are included to track the errors that can reduce our F1 score.*","metadata":{}},{"cell_type":"markdown","source":"Define model with metrics, training step and inference step coded using the Tensorflow model subclassing API. This allows training and checkpoints to be conducted directly through model.fit().","metadata":{}},{"cell_type":"code","source":"class MatchPredictor(keras.Model):\n\n    def __init__(self, image_units, title_units, metric_units, name='MatchPredictor', **kwargs):\n        super().__init__(name=name, **kwargs)\n        \n        self.image_units = image_units\n        self.title_units = title_units\n        self.metric_units = metric_units\n        \n        self.loss_tracker = keras.metrics.Mean(name=\"loss\")  \n        self.triplet_ratio_tracker = keras.metrics.Mean(name=\"triplet_ratio\")\n        self.recall_tracker = keras.metrics.Mean(name=\"recall\")\n        self.precision_tracker = keras.metrics.Mean(name=\"precision\")\n        self.f1_tracker = keras.metrics.Mean(name=\"f1_score\")\n    \n    def get_config(self):\n        config = {'image_units': self.image_units, 'title_units': self.title_units, 'metric_units': self.metric_units}\n        return config   \n \n    def build(self, input_shape):\n\n        # Encoder params\n        image_shape = input_shape[0][0][1:]\n        self.product_encoder = ProductEncoder(self.image_units, self.title_units, image_shape)\n\n        # Metric params\n        encoded_image_shape = self.product_encoder.output_shape[0][-1:]  # drops batch dim\n        encoded_title_shape = [self.title_units]  #self.product_encoder.output_shape[1][-1:] \n        encoded_phash_shape = self.product_encoder.output_shape[2][-2:]  \n                \n        self.product_metric = PseudoMetric(self.metric_units, encoded_image_shape, encoded_title_shape, encoded_phash_shape)\n\n    def call(self, inputs, **kwargs):\n        # Inputs   \n        product_1 = inputs[0]\n        product_2 = inputs[1]\n        \n        # Encode Products\n        image_encoding_1, title_encoding_1, phash_1 = self.product_encoder(product_1)\n        image_encoding_2, title_encoding_2, phash_2 = self.product_encoder(product_2)\n\n        # Compute product distances\n        distance = self.product_metric([image_encoding_1, title_encoding_1, phash_1, \n                                        image_encoding_2, title_encoding_2, phash_2])    \n        return distance\n    \n    def encoder(self, inputs, **kwargs):\n        \n        # Encode Products\n        image_encoding, title_encoding, phash = self.product_encoder(inputs)\n  \n        return image_encoding, title_encoding, phash\n    \n    def train_step(self, data):  \n        \"\"\" Strategy: One-shot learning via Siamese Network \"\"\"        \n        product_1 = data[0:3]\n        product_2 = data[3:6]\n        product_3 = data[6:9]\n               \n        # forward pass\n        with tf.GradientTape() as tape:\n            tape.watch(self.trainable_variables)\n            \n            matching_dist = self([product_1, product_2], training=True)                \n            non_matching_dist = self([product_1, product_3], training=True)       \n            \n            loss = (matching_dist + (1 - non_matching_dist)) / 2.\n            loss = tf.math.reduce_mean(loss)\n\n        # compute grads and apply updates\n        grads = tape.gradient(loss, self.trainable_variables)\n        grads = [tf.clip_by_norm(g, 10.) for g in grads]  # clipping\n        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n        \n        # Update metrics\n        self.loss_tracker.update_state(loss)   \n        self.compiled_metrics.update_state(matching_dist, non_matching_dist)\n        \n        # additional metrics        \n        self.triplet_ratio_tracker.update_state(\n            self.triplet_ratio(matching_dist, non_matching_dist)\n        )\n        self.precision_tracker.update_state(\n            self.precision(matching_dist, non_matching_dist, soft=False)\n        )\n        self.recall_tracker.update_state(\n            self.recall(matching_dist, non_matching_dist, soft=False)\n        )\n        self.f1_tracker.update_state(\n            self.f1_score(matching_dist, non_matching_dist, soft=False)\n        )\n\n        # Return a dict mapping metric names to current value\n        return {m.name: m.result() for m in self.metrics}\n        \n    def predict_step(self, data):\n        product_1 = data[0][0]       \n        product_2 = data[0][1]\n        \n        # Encode Products\n        image_encoding_1, title_encoding_1, phash_1 = self.product_encoder(product_1)\n        image_encoding_2, title_encoding_2, phash_2 = self.product_encoder(product_2)\n\n        # Compute product distances\n        distance = self.product_metric([image_encoding_1, title_encoding_1, phash_1, \n                                        image_encoding_2, title_encoding_2, phash_2])\n        \n        return tf.math.less_equal(distance, .5)  # predict match=True when distance is small\n    \n    def ProductEncoder(self, product):\n        return self.product_encoder(product)\n    \n    def PseudoMetric(self, encoded_product_pair):\n        product_1, product_2 = encoded_product_pair\n        return self.product_metric([product_1, product_2]) \n    \n    # LOSSES    \n    def false_neg(self, matching_dist, non_matching_dist, soft):\n        # count of matching products predicted as non-matching\n        if soft:\n            return matching_dist\n        else:\n            return tf.cast(tf.greater(matching_dist, .5), tf.float32)\n    \n    def false_pos(self, matching_dist, non_matching_dist, soft):\n        # nonmatching products named matching\n        if soft:\n            return 1 - non_matching_dist\n        else:\n            return tf.cast(tf.less_equal(non_matching_dist, .5), tf.float32)\n    \n    def true_neg(self, matching_dist, non_matching_dist, soft):\n        # note: non_matching products correctly classified\n        if soft:\n            return non_matching_dist\n        else:\n            return tf.cast(tf.greater(non_matching_dist, .5), tf.float32)\n    \n    def true_pos(self, matching_dist, non_matching_dist, soft):\n        # note: matching products correctly classified\n        if soft:\n            return 1 - matching_dist\n        else:\n            return tf.cast(tf.less_equal(matching_dist, .5), tf.float32)\n    \n    def precision(self, matching_dist, non_matching_dist, soft):\n        # percent of predictions that are correct\n        false_pos = tf.reduce_sum(self.false_pos(matching_dist, non_matching_dist, soft))\n        true_pos = tf.reduce_sum(self.true_pos(matching_dist, non_matching_dist, soft))\n        return true_pos / (true_pos + false_pos + 1e-7)\n        \n    def recall(self, matching_dist, non_matching_dist, soft):\n        # percent of \"positive\" ground truth examples identified\n        false_neg = tf.reduce_sum(self.false_neg(matching_dist, non_matching_dist, soft))\n        true_pos = tf.reduce_sum(self.true_pos(matching_dist, non_matching_dist, soft))\n        return true_pos / (true_pos + false_neg + 1e-7)\n        \n    def f1_score(self, matching_dist, non_matching_dist, soft):\n        precision = self.precision(matching_dist, non_matching_dist, soft)\n        recall = self.recall(matching_dist, non_matching_dist, soft)\n        return 2. * precision * recall / (precision + recall + 1e-7)\n\n    def triplet_ratio(self, matching_dist, non_matching_dist):\n        loss = (matching_dist + 1e-7) / (non_matching_dist + 1e-7)    \n        return tf.reduce_mean(loss, axis=-1)\n    \n    @property\n    def metrics(self):\n        return [self.loss_tracker, self.triplet_ratio_tracker, self.recall_tracker, self.precision_tracker, self.f1_tracker]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initialize and build model","metadata":{}},{"cell_type":"code","source":"# params\nfor triplet in triples_ds_train.take(1): \n    image_1 = triplet[0]\n    title_1 = triplet[1]\n    phash_1 = triplet[2]\n    \n    image_shape = image_1.shape[1:]\n    batch_size = image_1.shape[0]\n    phash_units = phash_1.shape[-1]\n    \n    product_1 = triplet[0:3]\n    product_2 = triplet[3:6]\n    product_3 = triplet[6:9]\n\nimage_units = 50\ntitle_units = phash_units\nmetric_units = 1\n    \n\n# Initialize and build Full Model\nMatchPredictorModel = MatchPredictor(image_units, title_units, metric_units)\nMatchPredictorModel([product_1, product_2])\n\n# Load weights\ntry:\n    #** Choose ONE of the below options **\n    # WARNING: loads weights from saved notbook outbook directory NOT the working directory!!\n    MatchPredictorModel.load_weights(PARAMETERS.saved_weights_dir())  \n    \n    # Warning: loads weights from working directory, NOT previously saved notebook outputs\n    #MatchPredictorModel.load_weights('saved_weights')  \n    print('Loaded saved weights.')\nexcept:\n    print('No weights loaded.')\n    \nMatchPredictorModel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"Training Loop","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# optional Tensorboard callback\n# This code works on Google Colab, but not Kaggle.\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, #histogram_freq=1,\n                                                       profile_batch=1)\n\n#%reload_ext tensorboard\n#%tensorboard --logdir=logs\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run model.fit()","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('./checkpoints', monitor='loss', save_weights_only=True, \n    save_freq='epoch')\n\n# compile model\nMatchPredictorModel.compile(optimizer=tf.keras.optimizers.Adagrad(.001))\n\n   \nMatchPredictorModel.fit(triples_ds_train, batch_size=128, epochs=1, steps_per_epoch=100,\n                        callbacks=[checkpoint], verbose=2, use_multiprocessing=True)\n\n# check for NaN\nfor triplet in triples_ds_train.take(1): \n\n    product_1 = triplet[0:3]\n    product_2 = triplet[3:6]\n    product_3 = triplet[6:9]\n\n# check for NaN\nprint(MatchPredictorModel.product_encoder(product_1)[0])\nprint(MatchPredictorModel.product_encoder(product_1)[1])\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MatchPredictorModel.save_weights('saved_weights')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n\n#### *Inference is a two-step process. Each image is run once through the encoder network, with encodings saved in a dictionary. We then run pairwise comparisons in order to categorize images into product groups and record the resulting groups in a CSV file for submission. With 70,000+ images, a reduction in pairwise comparions is required in order to keep within a manageable processing time. This reduction is accomplished by noting that (if predicted accurately), a positively matched (A, [A, B, C]) comparison automatically identifies matchings (B, [A, B, C]) and (C, [A, B, C]), and identifies that none of these elements can match with any other image group.*","metadata":{}},{"cell_type":"markdown","source":"Function to collect product encodings","metadata":{}},{"cell_type":"code","source":"\"\"\"\nfor triplet in triples_ds_train.skip(20).take(5): \n    image_1 = triplet[0]\n    title_1 = triplet[1]\n    phash_1 = triplet[2]\n    \n    image_shape = image_1.shape[1:]\n    batch_size = image_1.shape[0]\n    phash_units = phash_1.shape[-1]\n    \n    product_1 = triplet[0:3]\n    product_2 = triplet[3:6]\n    product_3 = triplet[6:9]\n\n    # forward pass\n    matching_dist = MatchPredictorModel([product_1, product_2])                \n    non_matching_dist = MatchPredictorModel([product_1, product_3])   \n    \n    image_encoding_1, title_encoding_1, phash_1 = MatchPredictorModel.product_encoder(product_1)\n    image_encoding_2, title_encoding_2, phash_2 = MatchPredictorModel.product_encoder(product_2)\n        \nfor single in single_ds_valid.take(1): \n    image_1 = single[0]\n    title_1 = single[1]\n    phash_1 = single[2]\n    \n    image_shape = image_1.shape[1:]\n    batch_size = image_1.shape[0]\n    phash_units = phash_1.shape[-1]\n    \n    product_1 = triplet[0:3]\n    \n    #print(product_1[0].shape, product_1[1].shape, product_1[2].shape)\n    print(MatchPredictorModel.ProductEncoder(single[:3]))\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_batch_encodings_ds(singles_ds, batch_size):\n\n    encoded_ds = None\n    for prod_with_id in singles_ds:\n        \n        # separate out id's\n        products = prod_with_id[:3]\n        product_ids = prod_with_id[3]\n\n        # encoder   \n        image_encoding, title_encoding, phash_encoding = MatchPredictorModel.ProductEncoder(products)\n\n        # sub-dataset\n        image_ds = tf.data.Dataset.from_tensor_slices(image_encoding)\n        title_ds = tf.data.Dataset.from_tensor_slices(title_encoding)\n        phash_ds = tf.data.Dataset.from_tensor_slices(phash_encoding)\n        product_id_ds = tf.data.Dataset.from_tensor_slices(product_ids)\n        \n        # combine sub-datasets\n        batch_ds = tf.data.Dataset.zip((image_ds, title_ds, phash_ds, product_id_ds))\n        \n        # update full dataset\n        if encoded_ds is None:\n            encoded_ds = batch_ds\n        else:\n            encoded_ds = encoded_ds.concatenate(batch_ds)\n\n    print('complete')\n\n    return encoded_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the function on our validation set","metadata":{}},{"cell_type":"code","source":"\"\"\"\nencoding_ds_valid = get_batch_encodings_ds(singles_ds=single_ds_valid.take(1000), \n                                           batch_size=256)  # use same batch size as in training\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to make predictions and save to CSV","metadata":{}},{"cell_type":"code","source":"def collect_predictions(encoded_ds, batch_size, for_submission, save_frequency=1000):\n    \n    # initialize containers and dataset\n    matches_dict = {}\n    comparison_ds = encoded_ds.batch(batch_size, drop_remainder=True).prefetch(5)\n    completed_predictions = set([])\n    \n    # utility function for saving intermediate & final results   \n    def save_results(matches_dict, number=None):\n        df = pd.DataFrame.from_dict(matches_dict, orient='index')\n        df = df.fillna('**')\n        df = df.apply(lambda x: ', '.join(x), axis=1)\n        df = df.apply(lambda x: x.replace(', **', ''))#, axis=1)\n        df.index.name = 'posting_id'\n        df.name = 'matches'\n\n        # update filename\n        if number is None:\n            number = ''\n        else:\n            number = '' + number\n        \n        if for_submission:\n            filename = 'submission.csv'\n        else:\n            filename = 'train_submission' + number + '.csv'\n        with open(filename, 'w') as f:\n            df.to_csv(filename, index=True)\n        return df\n    \n    i = 1\n    for prod1 in encoded_ds.batch(1).prefetch(5):\n        \n        # separate encoding and id\n        encoded_prod_1 = prod1[:3]\n        post_id_1 = prod1[3].numpy()[0].decode()  # extract and convert to string      \n        \n        if post_id_1 in completed_predictions:\n            continue\n\n        # make sure to self-match\n        matches_dict[post_id_1] = set([post_id_1])\n       \n        # replicate product for broadcasting against batches        \n        encoding_1_ds = tf.data.Dataset.from_tensors(encoded_prod_1)     \n        encoding_1_ds = encoding_1_ds.unbatch().repeat(batch_size).batch(batch_size)\n        \n        # compare with comparison product encodings\n        for comparison_batch in comparison_ds:\n            \n            # make sure batch sizes match\n            current_batch_size = comparison_batch[0].shape[0]\n            if batch_size != current_batch_size:\n                temp_ds = tf.data.Dataset.from_tensor_slices((comparison_batch))\n                temp_ds = temp_ds.unbatch().repeat(current_batch_size).batch(current_batch_size)\n                \n                for val in temp_ds.take(1):\n                    comparison_batch = val\n            \n            # get encodings and ids\n            comparison_encodings = comparison_batch[:3]\n            comparison_product_id = comparison_batch[3]\n \n            for encoding_1 in encoding_1_ds.take(1):\n                \n                # Compute product distances\n                distance = MatchPredictorModel.PseudoMetric([encoding_1, comparison_encodings])\n \n                # make predictions\n                predictions = tf.math.less_equal(distance, 1.1)  # predict match=True when distance is small\n \n                # decode matches\n                predictions = np.squeeze(predictions.numpy())\n                matching_prod_ids = comparison_product_id.numpy()[predictions]\n                matching_prod_ids = matching_prod_ids.tolist()\n                matching_prod_ids = [prod_id.decode() for prod_id in matching_prod_ids]\n                \n                # record matches\n                matches_dict[post_id_1].update(matching_prod_ids)\n        \n        # assume prediction correct, so that all products in group have identical solutions\n        for post in matches_dict[post_id_1]:\n            matches_dict[post] = matches_dict[post_id_1]\n            \n        # mark as completed\n        completed_predictions.update(matches_dict[post_id_1])\n        \n        # report and save progress\n        if i % 100 == 0:\n            print('completed_predictions:', len(completed_predictions))          \n        if i % save_frequency == 0:\n            _ = save_results(matches_dict, number='i')\n\n        # advance counter\n        i += 1\n\n    # save final results\n    df = save_results(matches_dict, number='')\n    print('finished')     \n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the function on our validation set","metadata":{}},{"cell_type":"code","source":"#matches_df_valid = collect_predictions(encoded_ds=encoding_ds_valid.take(1000), batch_size=256, for_submission=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#matches_df_valid.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Function to compute F1 scores (model evaluation on validation set)","metadata":{}},{"cell_type":"code","source":"def compute_f1_score(matches_dict, data_df):\n\n    f1_score_mean_accumulator = keras.metrics.Mean(name='f1_mean')\n    i=0\n    for prod_num in matches_dict:\n    \n        # find correct matches from dataframe\n        group_id = data_df.loc[prod_num]['label_group']\n        correct_matches = set(data_df[data_df['label_group'] == group_id].index.to_list())\n        our_matches = set(matches_dict[prod_num])\n\n        \n        true_pos_count = len(our_matches.intersection(correct_matches))\n        false_pos_count = len(our_matches.difference(correct_matches))\n        actual_pos_count = len(correct_matches)\n        \n        print('correct_matches:', correct_matches)\n        print('true_pos_count:', true_pos_count)\n        print('false_pos_count:', false_pos_count)\n        print('actual_pos_count:', actual_pos_count)\n\n        precision = true_pos_count / (true_pos_count + false_pos_count)\n        recall = true_pos_count / (actual_pos_count)\n        f1 = 2 * precision * recall / (precision + recall)\n        f1_score_mean_accumulator.update(f1)\n        \n        print('precision:', precision)\n        print('recall:', recall)\n        \n        if i % 100 ==0:\n            print('mean f1_score:', f1_score_mean_accumulator.result())\n\n        break\n    print('finished')   \n    print('final f1_score:', f1_score_mean_accumulator.result())\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compute_f1_score(matches_dict=matches_df_valid.to_dict(), data_df=VALID_DF)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FINAL INFERENCE SUBMISION CREATION","metadata":{}},{"cell_type":"markdown","source":"Run these functions to generate submission on the test set","metadata":{}},{"cell_type":"code","source":"# INFERENCE DATA PREP\n\n\n# load inference csv as dataframe\nfile_dir = PARAMETERS.dataset_dir()\n\ninference_DF = pd.read_csv(file_dir + 'test.csv')\ninference_DF['id'] = inference_DF['posting_id']\ninference_DF = inference_DF.set_index('id')\ninference_DF['title'] = inference_DF['title'].apply(lambda x: x.lower())\ninference_DF = inference_DF.rename(columns={'image':'image_path'})\n\n# pre-processing step\nfile_dir = PARAMETERS.prep_save_dir()\ninference_single_product_df = create_single_product_df(inference_DF)\nsave_to_csv(file_dir + 'inference_single_product_df.csv', inference_single_product_df)\n\n# load singles datasets from csv\nfile_dir = PARAMETERS.prep_save_dir()\n\n# create dataset\nsingle_ds_inference = create_singles_ds_from_csv(inference_csv = file_dir + 'inference_single_product_df.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get encodings\nencoding_ds_inference = get_batch_encodings_ds(singles_ds=single_ds_inference, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions\nmatches_df_inference = collect_predictions(encoded_ds=encoding_ds_inference, \n                                       batch_size=128, for_submission=True, save_frequency=250)\nmatches_df_inference.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}